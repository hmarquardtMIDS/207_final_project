{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqgMcK85FLTo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import matplotlib.image as mpimg\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import constants\n",
        "\n",
        "labels = pd.read_csv(constants.LABELS_PATH_CROPPED)\n",
        "labels.head()"
      ],
      "metadata": {
        "id": "eWQrQjtOFOTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotive = labels[labels['label']!= \"Neutral\"]\n",
        "\n",
        "# I want to maintain the original label for analysis at the end of the model\n",
        "emotive.loc[:, 'label'] = 'Emotive'\n",
        "neutral = labels[labels['label'] == \"Neutral\"]\n",
        "neutral.loc[:, 'label'] = 'Neutral'\n",
        "print(f\"{len(emotive) = }\")\n",
        "print(f\"{len(neutral) = }\")"
      ],
      "metadata": {
        "id": "NugVJKGnFP1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_binary = pd.concat([emotive, neutral])\n",
        "print(df_binary.head())\n",
        "print(df_binary.tail())"
      ],
      "metadata": {
        "id": "WDF017SxFRs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_ENCODE_DICT = {\n",
        "    'Emotive': 1,\n",
        "    'Neutral': 0\n",
        "}"
      ],
      "metadata": {
        "id": "G7AXIEPIFTGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_label(df, encoder_dict):\n",
        "    \"\"\"returns df where label column is encoded\"\"\"\n",
        "    df['label_encoded'] = df['label'].map(encoder_dict)\n",
        "    return df\n",
        "\n",
        "encode_label(df_binary, LABEL_ENCODE_DICT)"
      ],
      "metadata": {
        "id": "xWsM8GMFFVwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import preprocessing"
      ],
      "metadata": {
        "id": "KVnBkvtKFXI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = preprocessing.preprocess_data_part1(df_binary, constants.IMAGES_FOLDER_PATH)\n",
        "X_grey, y_grey = preprocessing.preprocess_data_part1(df_binary, constants.IMAGES_FOLDER_PATH, greyscale=True)\n",
        "\n",
        "print(f\"images shape {X.shape}\")\n",
        "print(f\"y shape {y.shape}\")\n",
        "print(f\"grey images shape {X_grey.shape}\")\n",
        "print(f\"grey y shape {y_grey.shape}\")"
      ],
      "metadata": {
        "id": "-NUcva7bFYqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose 5 random indices\n",
        "random_indices = np.random.choice(X.shape[0], size=5, replace=False)\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
        "# Iterate over the random indices and display the images\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Display the image\n",
        "    axes[i].imshow(X[idx] / 255.0)  # Scale pixel values to [0, 1] for display\n",
        "    axes[i].set_title(f\"Label: {y[idx]}\\nShape: {X[idx].shape[0]}x{X[idx].shape[1]}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EbqtbQwuFaPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure and axes\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
        "# Iterate over the random indices and display the images\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Display the image\n",
        "    axes[i].imshow(X_grey[idx] / 255.0)  # Scale pixel values to [0, 1] for display\n",
        "    axes[i].set_title(f\"Label: {y_grey[idx]}\\nShape: {X_grey[idx].shape[0]}x{X_grey[idx].shape[1]}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sSyTPyhzFcOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define splits\n",
        "split = (0.6, 0.2, 0.2)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocessing.data_split_and_augment(X, y, split)\n",
        "\n",
        "X_train_grey, y_train_grey, X_val_grey, y_val_grey, X_test_grey, y_test_grey = preprocessing.data_split_and_augment(X_grey, y_grey, split)\n",
        "\n",
        "\n",
        "print(f\"X_train shape {X_train.shape}\")\n",
        "print(f\"y_train shape {y_train.shape}\")\n",
        "print(f\"X_val shape {X_val.shape}\")\n",
        "print(f\"y_val shape {y_val.shape}\")\n",
        "print(f\"X_test shape {X_test.shape}\")\n",
        "print(f\"y_test shape {y_test.shape}\")\n",
        "print(f\"X_train_grey shape {X_train_grey.shape}\")\n",
        "print(f\"X_val_grey shape {X_val_grey.shape}\")\n",
        "print(f\"X_test_grey shape {X_test_grey.shape}\")"
      ],
      "metadata": {
        "id": "cFJox4TzFdzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the X and Y arrays to free up more space in RAM\n",
        "del X\n",
        "del y"
      ],
      "metadata": {
        "id": "CVv9TOxuoJqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n, bins, patches = plt.hist(y_train, bins=2, edgecolor='black', align='mid')\n",
        "\n",
        "# Set colors for the bars\n",
        "colors = ['skyblue', 'salmon']\n",
        "for i, patch in enumerate(patches):\n",
        "    patch.set_facecolor(colors[i])\n",
        "\n",
        "# Set labels for the x-axis and y-axis\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Set ticks to show labels for classes\n",
        "plt.xticks([.25, .75], ['Neutral', 'Emotive'])\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution of Neutral vs. Emotive')\n",
        "\n",
        "# Add labels in the middle of the bars\n",
        "for patch in patches:\n",
        "    height = patch.get_height()\n",
        "    # Calculate the x position of the label (middle of the bar)\n",
        "    x = patch.get_x() + patch.get_width() / 2\n",
        "    # Add the label with the height value\n",
        "    plt.text(x, height, str(int(height)), ha='center', va='bottom')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hqb9MF8OoLXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of 'Neutral' instances\n",
        "neutral_count = np.sum(y_train == 0)\n",
        "\n",
        "# Find indices of 'Emotive' instances\n",
        "emotive_indices = np.where(y_train == 1)[0]\n",
        "\n",
        "# Randomly select 'Emotive' indices to remove to match the 'Neutral' count\n",
        "indices_to_remove = np.random.choice(emotive_indices, size=len(emotive_indices) - neutral_count, replace=False)\n",
        "\n",
        "# Remove the selected 'Emotive' instances from X_train and y_train\n",
        "X_train_balanced = np.delete(X_train, indices_to_remove, axis=0)\n",
        "y_train_balanced = np.delete(y_train, indices_to_remove, axis=0)\n",
        "\n",
        "X_train_balanced_grey = np.delete(X_train_grey, indices_to_remove, axis=0)\n",
        "y_train_balanced_grey = np.delete(y_train_grey, indices_to_remove, axis=0)\n",
        "\n",
        "\n",
        "n, bins, patches = plt.hist(y_train_balanced, bins=2, edgecolor='black', align='mid')\n",
        "\n",
        "# Set colors for the bars\n",
        "colors = ['skyblue', 'salmon']\n",
        "for i, patch in enumerate(patches):\n",
        "    patch.set_facecolor(colors[i])\n",
        "\n",
        "# Set labels for the x-axis and y-axis\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Set ticks to show labels for classes\n",
        "plt.xticks([.25, .75], ['Neutral', 'Emotive'])\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution of Neutral vs. Emotive')\n",
        "\n",
        "# Add labels in the middle of the bars\n",
        "for patch in patches:\n",
        "    height = patch.get_height()\n",
        "    # Calculate the x position of the label (middle of the bar)\n",
        "    x = patch.get_x() + patch.get_width() / 2\n",
        "    # Add the label with the height value\n",
        "    plt.text(x, height, str(int(height)), ha='center', va='bottom')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "print(X_train_balanced.shape)\n",
        "print(y_train_balanced.shape)"
      ],
      "metadata": {
        "id": "CiK3kuPkoQ6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Model"
      ],
      "metadata": {
        "id": "C3zxqBLSobs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "class MajorityClassModel:\n",
        "    \"\"\" A dummy model that always predicts the majority class \"\"\"\n",
        "    def __init__(self, majority_class):\n",
        "        self.majority_class = majority_class\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.majority_class] * len(X))\n",
        "\n",
        "    def evaluate(self, X, y_true):\n",
        "        y_pred = self.predict(X)\n",
        "        accuracy = round(accuracy_score(y_true, y_pred), 4)\n",
        "        return accuracy"
      ],
      "metadata": {
        "id": "AnzmSFVwoaEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the most frequent value in y_train (\n",
        "class_frequencies = np.unique(y_train, return_counts=True)\n",
        "majority_class = class_frequencies[0][np.argmax(class_frequencies[1])]\n",
        "print(f\"{majority_class = }\")\n",
        "\n",
        "# Initialize the model\n",
        "base_model = MajorityClassModel(majority_class)\n",
        "\n",
        "# # \"Train\" the model (no actual training needed for this dummy model)\n",
        "\n",
        "# Make predictions on validation and test sets\n",
        "y_val_pred = base_model.predict(X_val)  # Replace val_df with actual image data if available\n",
        "y_test_pred = base_model.predict(X_test)  # Replace test_df with actual image data if available\n",
        "\n",
        "\n",
        "# Evaluate the model, rounded to 3 decimals\n",
        "val_accuracy = base_model.evaluate(X_val, y_val)\n",
        "test_accuracy = base_model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "Am0fpuxUoe1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model_accuracy = pd.DataFrame({\n",
        "    'Model': ['Baseline'],\n",
        "    'Training Accuracy': [base_model.evaluate(X_train, y_train)],\n",
        "    'Validation Accuracy': [val_accuracy],\n",
        "    'Test Accuracy': [test_accuracy],\n",
        "    'Color?': ['Yes']\n",
        "})\n",
        "df_model_accuracy"
      ],
      "metadata": {
        "id": "Zs9yjz1eogwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grey_row = {\n",
        "    'Model': 'Baseline',\n",
        "    'Training Accuracy': base_model.evaluate(X_train_grey, y_train_grey),\n",
        "    'Validation Accuracy': val_accuracy,\n",
        "    'Test Accuracy': test_accuracy,\n",
        "    'Color?': 'No'\n",
        "}\n",
        "\n",
        "# Using append (deprecated)\n",
        "# df = df.append(new_row, ignore_index=True)\n",
        "\n",
        "# Using concat (recommended)\n",
        "df_model_accuracy = pd.concat([df_model_accuracy, pd.DataFrame([grey_row])], ignore_index=True)\n",
        "df_model_accuracy"
      ],
      "metadata": {
        "id": "DHAsGa8noiwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build our Basic Binary Model With the Balanced Training Set\n"
      ],
      "metadata": {
        "id": "qMlEc2KSonN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define an instance of the early_stopping class\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "monitor='accuracy',\n",
        "verbose=1,\n",
        "patience=4,\n",
        "mode='max',\n",
        "restore_best_weights=True)"
      ],
      "metadata": {
        "id": "_ZZQQaezok8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicCNNModel:\n",
        "    def __init__(self, input_shape, learning_rate=0.001):\n",
        "        self.model = self.create_cnn_model()\n",
        "        self.model.build(input_shape=input_shape)\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                           loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "    def create_cnn_model(self):\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.Conv2D(filters=12, kernel_size=(4, 4), strides=(1, 1), padding='same',\n",
        "                                         data_format='channels_last', name='conv_1', activation='relu'))\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(tf.keras.layers.Dropout(0.3))\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "    def summary(self):\n",
        "        self.model.summary()\n",
        "\n",
        "    def fit(self, X_train, y_train, epochs, validation_data, callbacks):\n",
        "        self.model.fit(X_train, y_train, epochs=epochs, validation_data=validation_data, callbacks=callbacks)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        return self.model.evaluate(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# Example usage\n",
        "# Assuming X_train_balanced, y_train_balanced, X_val, y_val are already defined\n",
        "input_shape = (None, 180, 120, 3)\n",
        "\n",
        "cnn_model_color = BasicCNNModel(input_shape=input_shape, learning_rate = .0001)\n",
        "cnn_model_color.summary()\n",
        "cnn_model_color.fit(X_train_balanced, y_train_balanced, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "train_acc_cnn_color = cnn_model_color.evaluate(X_train_balanced, y_train_balanced)\n",
        "val_acc_cnn_color = cnn_model_color.evaluate(X_val, y_val)\n",
        "\n",
        "print(\"Training Accuracy:\", train_acc_cnn_color[1])\n",
        "print(\"Validation Accuracy:\", val_acc_cnn_color[1])"
      ],
      "metadata": {
        "id": "LiOiUZEzopiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Same Model on the Grey-Scale Data"
      ],
      "metadata": {
        "id": "UbQtnhPsot2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape_grey = (None, 180, 120, 1)\n",
        "\n",
        "cnn_model_grey = BasicCNNModel(input_shape=input_shape_grey, learning_rate = .0001)\n",
        "cnn_model_grey.summary()\n",
        "cnn_model_grey.fit(X_train_balanced_grey, y_train_balanced_grey, epochs=10, validation_data=(X_val_grey, y_val_grey), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "train_acc_cnn_grey = cnn_model_grey.evaluate(X_train_balanced_grey, y_train_balanced_grey)\n",
        "val_acc_cnn_grey = cnn_model_grey.evaluate(X_val_grey, y_val_grey)\n",
        "\n",
        "print(\"Training Accuracy Greyscale:\", train_acc_cnn_grey[1])\n",
        "print(\"Validation Accuracy Greyscale:\", val_acc_cnn_grey[1])"
      ],
      "metadata": {
        "id": "TMMYNVA7osJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_cnn = cnn_model.evaluate(X_test, y_test)\n",
        "\n",
        "new_row = {'Model': 'Basic CNN', 'Training Accuracy': train_acc_cnn[1], 'Validation Accuracy': val_acc_cnn[1],\n",
        "    'Test Accuracy': test_acc_cnn[1]}\n",
        "\n",
        "# Using append (deprecated)\n",
        "# df = df.append(new_row, ignore_index=True)\n",
        "\n",
        "# Using concat (recommended)\n",
        "df_model_accuracy = pd.concat([df_model_accuracy, pd.DataFrame([new_row])], ignore_index=True)\n",
        "df_model_accuracy"
      ],
      "metadata": {
        "id": "5ouvTv0qoxXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: using certain indices of X_train, plot the image with the real label next to the predicted label the model would give it\n",
        "\n",
        "# Choose 5 random indices from indices_to_remove\n",
        "random_indices = np.random.choice(indices_to_remove, size=5, replace=False)\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
        "\n",
        "# Iterate over the random indices and display the images with predictions\n",
        "for i, idx in enumerate(random_indices):\n",
        "    image = X_train[idx]\n",
        "    # original_label = df_binary.loc[idx, 'original_label']\n",
        "    true_label = y_train[idx]\n",
        "\n",
        "    # Make a prediction for the image\n",
        "    prediction = cnn_model.predict(np.expand_dims(image, axis=0))\n",
        "    predicted_label = \"Emotive\" if prediction > 0.5 else \"Neutral\"\n",
        "\n",
        "    # Display the image\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].set_title(f\"True: {true_label}\\nPredicted: {predicted_label}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m8vNhqTHo0QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Complex CNN (Hima's Model)"
      ],
      "metadata": {
        "id": "EXwG9nufo5pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "class ComplexCNNModel:\n",
        "    def __init__(self, input_shape, learning_rate=0.001):\n",
        "        self.input_shape = input_shape\n",
        "        self.learning_rate = learning_rate\n",
        "        self.model = self.create_complex_cnn_model()\n",
        "\n",
        "    def create_complex_cnn_model(self):\n",
        "        model = Sequential()\n",
        "        # 1st Convolutional layer\n",
        "        model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=self.input_shape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # 2nd Convolutional layer\n",
        "        model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # 3rd Convolutional layer\n",
        "        model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "        # Flattening layer\n",
        "        model.add(Flatten())\n",
        "        # 1st Dense layer\n",
        "        model.add(Dense(units=512, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        # 2nd Dense layer\n",
        "        model.add(Dense(units=256, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        # Output layer\n",
        "        model.add(Dense(units=1, activation='sigmoid'))  # For binary classification\n",
        "        # Compile the model\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def summary(self):\n",
        "        self.model.summary()\n",
        "\n",
        "    def fit(self, X_train, y_train, epochs, batch_size, validation_data, callbacks):\n",
        "        self.history = self.model.fit(X_train, y_train,\n",
        "                                      epochs=epochs,\n",
        "                                      batch_size=batch_size,\n",
        "                                      validation_data=validation_data,\n",
        "                                      callbacks=callbacks)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        return self.model.evaluate(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# Example usage\n",
        "# Assuming X_train, y_train, X_val, y_val are already defined and preprocessed\n",
        "input_shape = (180, 120, 3)  # Update this to match your input data shape\n",
        "\n",
        "cnn_model2 = ComplexCNNModel(input_shape=input_shape)\n",
        "cnn_model2.summary()\n",
        "\n",
        "cnn_model2.fit(X_train_balanced, y_train_balanced, epochs=10, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "train_loss_complex, train_accuracy_complex = cnn_model2.evaluate(X_train_balanced, y_train_balanced)\n",
        "val_loss_complex, val_accuracy_complex = cnn_model2.evaluate(X_val, y_val)\n",
        "\n",
        "print(\"Training loss:\", train_loss_complex)\n",
        "print(\"Training accuracy:\", train_accuracy_complex)\n",
        "print(\"Validation loss:\", val_loss_complex)\n",
        "print(\"Validation accuracy:\", val_accuracy_complex)\n",
        "\n",
        "# # Predict on new data\n",
        "# y_pred = cnn_model.predict(X_val)\n",
        "# print(\"Predictions:\", y_pred)"
      ],
      "metadata": {
        "id": "wOujeQnvo59G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_cnn2 = cnn_model.evaluate(X_test, y_test)[1]\n",
        "\n",
        "new_row2 = {'Model': 'Complex CNN', 'Training Accuracy': train_accuracy_complex, 'Validation Accuracy':val_accuracy_complex,\n",
        "    'Test Accuracy': test_acc_cnn2}\n",
        "\n",
        "# Using append (deprecated)\n",
        "# df = df.append(new_row, ignore_index=True)\n",
        "\n",
        "# Using concat (recommended)\n",
        "df_model_accuracy = pd.concat([df_model_accuracy, pd.DataFrame([new_row2])], ignore_index=True)\n",
        "df_model_accuracy"
      ],
      "metadata": {
        "id": "AMb_DLKro837"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}